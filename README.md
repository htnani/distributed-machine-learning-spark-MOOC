# Distributed Machine Learning with Apache Spark

Course files for UC Berkeley CS120x course on edX, Jul/Aug 2016.

The goal of this course is to learn the underlying principles required to develop scalable machine learning pipelines and gain hands-on experience using Apache Spark.

The code in this repository represents a sample of the work I completed in the course, and includes course assignments as I submitted them, as well as others I worked on after the completion of the course. 

Note that substantial portions of the code for this assignment were written by the course instructors, and the assignments consisted of filling in missing components of skeleton code--these notebooks were not written by me from scratch. Because this was a MOOC and I was utilizing the assignments as a learning opportunity to supplement my coursework, I also extensively utilized outside resources to complete these assignments, including the resources listed below:

* http://spark.apache.org/docs/latest/api/python/
* https://github.com/apache/spark/tree/master/python/pyspark
* https://spark.apache.org/docs/1.2.1/ml-guide.html
* https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-mllib-pipelines.html
* https://databricks.com/blog/2015/01/07/ml-pipelines-a-new-high-level-api-for-mllib.html
* https://youtu.be/OednhGRp938
